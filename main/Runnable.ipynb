{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4c1c13",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d5c8b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm_model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",temperature=0.7,api_key=os.environ[(\"GOOGLE_API_KEY\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632f6e8a",
   "metadata": {},
   "source": [
    "RUNNABLE PASS THORUGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2e0d159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello bro'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chains =  RunnablePassthrough()\n",
    "\n",
    "chains.invoke(\"hello bro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a3c3b9",
   "metadata": {},
   "source": [
    "RUNNABLE LAMBDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bb442e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def lamdba_fun(name):\n",
    "    return  f'Hi{name} , How how may i help you!'\n",
    "chains = RunnablePassthrough() | RunnableLambda(lamdba_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d45123ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi sujith , How how may i help you!'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chains.invoke(\" sujith\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb8a14",
   "metadata": {},
   "source": [
    "RUNNABLE PARALLEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1f65d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt_1 =ChatPromptTemplate.from_template(\"Hello i am {user_name}\")\n",
    "\n",
    "chains = RunnableParallel({\n",
    "    \"operation_1\" : RunnablePassthrough()    ,\n",
    "    \"user_name\": RunnableLambda(lamdba_fun),\n",
    "    \"operation_2\":RunnablePassthrough()\n",
    "}) | prompt_1 | llm_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e2d3114",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chains.invoke({\"user_name\":\"sujith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bab3578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Sujith!\\n\\nIt looks like there might have been a small mix-up in your message. You introduced yourself as Sujith, and then asked \"How may I help you!\"\\n\\nAs an AI, I\\'m actually here to help *you*! So, how can **I** help **you** today? Please tell me what you need assistance with, and I\\'ll do my best!'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abe1934",
   "metadata": {},
   "source": [
    "Item Getter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5bace7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='சுஜித்தின் GPA 8.45 ஆகும்.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--38aa5796-6521-42bc-b858-84f989e31870-0' usage_metadata={'input_tokens': 106, 'output_tokens': 194, 'total_tokens': 300, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 183}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm_model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",temperature=0.7,api_key=os.environ[(\"GOOGLE_API_KEY\")])\n",
    "\n",
    "\n",
    "from operator import itemgetter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.runnables import RunnablePassthrough , RunnableParallel\n",
    "\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")\n",
    "fiass = FAISS.from_texts([\"sujith is a cse student , he is a gamer , his marks is low but high at coding skills , great warrier , 8.45 gpa \"],embedding=embedding_model)\n",
    "retriever = fiass.as_retriever()\n",
    "\n",
    "templete = \"\"\"Answer the question {question} and here is the reference {context} and give the output in language{language}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(templete)\n",
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"language\": itemgetter(\"language\"),\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    ") | prompt | llm_model \n",
    "result = chain.invoke({\"question\": \"what  is Sujith gpa?\",\"language\":\"tamil\"})\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b63827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28847c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
