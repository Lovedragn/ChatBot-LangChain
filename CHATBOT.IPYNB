{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37463b8b",
   "metadata": {},
   "source": [
    "## IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1029bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd89a21d",
   "metadata": {},
   "source": [
    "# Completion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15bafe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Completion models\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "llm_model = GoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa5c4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "UPDATE table_name\n",
      "SET column1 = value1, column2 = value2, ...\n",
      "WHERE condition;\n",
      "```\n",
      "``` %sql\n",
      "UPDATE table_name\n",
      "SET column1 = value1, column2 % = value2, ...\n",
      "WHERE condition;\n",
      "```\n",
      " %"
     ]
    }
   ],
   "source": [
    "response = llm_model.invoke(\"write updation sq qurey simple and short no description\")\n",
    "print(response)\n",
    "\n",
    "for chunk in llm_model.stream(\"write updation sq qurey simple and short no description\"):\n",
    "    print(chunk , end=\" %\" , flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b7cc9",
   "metadata": {},
   "source": [
    "# CHAT MODEL⭐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdfba396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chatmodel \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm_chat_model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35db6bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage , HumanMessage\n",
    "message = [\n",
    "        SystemMessage(content=\"you are a helpful sql query generator,Just give short answeres & no arguments.\"),\n",
    "        HumanMessage(content=\"write a complex sql query to find the second highest salary from employee table\"),\n",
    "]\n",
    "response = llm_chat_model.invoke(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85be03d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```sql\\nSELECT MAX(salary) FROM employee WHERE salary < (SELECT MAX(salary) FROM employee);\\n```'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73521de5",
   "metadata": {},
   "source": [
    "# Prompt Templete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71ba4808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate # <- completion model support\n",
    "\n",
    "prompt_templete_completion_model = PromptTemplate.from_template(\"Write simple SQL query for {action} in table {table}\") \n",
    "\n",
    "request = prompt_templete_completion_model.format(table=\"user\",action=\"delete\")\n",
    "response = llm_model.invoke(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9381ac6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write simple SQL query for delete in table user'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa27ac4",
   "metadata": {},
   "source": [
    "# ChatPrompt Templete⭐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2206a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_templete_chat_model  = ChatPromptTemplate.from_messages([(\"system\",\"you are a {profession} specialist , Give short answers like 10 words\"),\n",
    "                                                                (\"human\",\"Hello, i am {name}\"),\n",
    "                                                                (\"ai\",\"{name} Sure!\"),\n",
    "                                                                (\"human\",\"{user_input}\")])\n",
    "\n",
    "\n",
    "request = prompt_templete_chat_model.format(profession=\"space researcher\",user_input=\"tell about sun\",name=\"sujith\")\n",
    "\n",
    "response = llm_chat_model.invoke(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd9dfe9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Massive, hot plasma sphere; nuclear fusion powerhouse; life's energy source.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--1311f1f9-c868-435b-b151-a1501cf9e4f5-0', usage_metadata={'input_tokens': 41, 'output_tokens': 17, 'total_tokens': 58, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac30bc0",
   "metadata": {},
   "source": [
    "# FewShort Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f92b5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are sql query writer.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'action': 'delete | remote | destory user_sujith', 'prompt': 'write sql query to delete the entire row of the given name user_xxx'}, {'action': 'update | change | modify from user_sujith to user_sappani', 'prompt': 'write sql query to update the entire row of the given name of user_xxx'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['action', 'prompt'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['action'], input_types={}, partial_variables={}, template='{action}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['prompt'], input_types={}, partial_variables={}, template='{prompt}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples=[{\"action\":\"delete | remote | destory user_sujith\",\"prompt\":\"write sql query to delete the entire row of the given name user_xxx\"},\n",
    "          {\"action\":\"update | change | modify from user_sujith to user_sappani\",\"prompt\":\"write sql query to update the entire row of the given name of user_xxx\"},\n",
    "            ]\n",
    "example_prompt = ChatPromptTemplate.from_messages([(\"human\",\"{action}\"),(\"ai\",\"{prompt}\")])\n",
    "\n",
    "request = FewShotChatMessagePromptTemplate(example_prompt=example_prompt,examples=examples)\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([(\"system\",\"you are sql query writer.\"),request,(\"human\",\"{input}\")])\n",
    "final_prompt\n",
    "# response = llm_chat_model.invoke(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f664fb3e",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc966b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples=[{\"action\":\"delete | remote | destory user_sujith\",\"prompt\":\"write sql query to delete the entire row of the given name user_xxx\"},\n",
    "          {\"action\":\"update | change | modify from user_sujith to user_sappani\",\"prompt\":\"write sql query to update the entire row of the given name of user_xxx\"},\n",
    "            ]\n",
    "example_prompt = ChatPromptTemplate.from_messages([(\"human\",\"{action}\"),(\"ai\",\"{prompt}\")])\n",
    "\n",
    "request = FewShotChatMessagePromptTemplate(example_prompt=example_prompt,examples=examples)\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([(\"system\",\"you are sql query writer.write only sql qureirs no descriptions.\"),request,(\"human\",\"{input}\")])\n",
    "chain =final_prompt | llm_chat_model\n",
    "\n",
    "response = chain.invoke({\"input\":\"update the user_xxx to user_sujith_star\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4b55c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "sql\n",
      "UPDATE users SET username = 'user_sujith_star'\n",
      " WHERE username = 'user_xxx';\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in chain.stream({\"input\":\"update the user_xxx to user_sujith_star\"}):\n",
    "    print(i.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4c7e83",
   "metadata": {},
   "source": [
    "# Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_templete = PromptTemplate.from_template(\"Return a JSON object with 'answer' key that answer the following sql qurstion :{user_input} from database {database},just return the sql query with json object\")\n",
    "\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "chian = prompt_templete | llm_model | json_parser\n",
    "\n",
    "result = chain.invoke({\"user_input\":\"add gardening at 12/12/2025\",\"database\":\"{title:'walking',date:'12/12/2025'}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0dfe882a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': \"INSERT INTO your_table (title, date) VALUES ('gardening', '2025-12-12');\"}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f395cc1b",
   "metadata": {},
   "source": [
    "# Advanced Parser⭐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "06bdd575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel , Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "class structure(BaseModel):\n",
    "    question : str = Field(description=\"question to setup the sql query table details short\")\n",
    "    answer : str = Field(description=\"only sql qurey to the question\")\n",
    "    \n",
    "parser = JsonOutputParser(pydantic_object=structure)\n",
    "prompt_templete = PromptTemplate(\n",
    "    template=\"Answer the sql questions from user {user_input} via database {database} and {format_instructions} \",\n",
    "    input_variables=[\"database\",\"user_input\"],\n",
    "    partial_variables={\"format_instructions\" : parser.get_format_instructions }\n",
    ")\n",
    "chain = prompt_templete | llm_chat_model | parser\n",
    "\n",
    "request = chain.invoke({\"user_input\":\"Add a gardening at 12/12/2025 \",\"database\":\"{Title:'bathing',Date:'12/12/2024'}\"} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f50bbfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Add a gardening at 12/12/2025  via database {Title:'bathing',Date:'12/12/2024'}\",\n",
       " 'answer': \"```sql\\nINSERT INTO your_table (Title, Date) VALUES ('Gardening', '2025-12-12');\\n```\"}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
