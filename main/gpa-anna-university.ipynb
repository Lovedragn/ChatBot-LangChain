{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50737b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional\n",
    "from datetime import date\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from operator import itemgetter\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load ENV + LLM\n",
    "# -----------------------------\n",
    "load_dotenv()\n",
    "llm_model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    api_key=os.environ[\"GOOGLE_API_KEY\"],\n",
    "    temperature=0.2  # ✅ keep deterministic for schema-based parsing\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load & Index Data (PDF)\n",
    "# -----------------------------\n",
    "pdf_loader = PyPDFLoader(\"D:\\\\NameKart\\\\React + SpringBoot\\\\ChatBot\\\\Resource\\\\B.E.CSE (1).pdf\")\n",
    "docs = pdf_loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "splits = splitter.split_documents(docs)\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")\n",
    "vector_db = FAISS.from_documents(splits, embedding_model)\n",
    "\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\":10})  # ✅ reduced from 800 to 10\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Subject Extractor (Grades → Numeric)\n",
    "# -----------------------------\n",
    "grade_converter = {\n",
    "    \"O\": 10, \"A+\": 9, \"A\": 8, \"B+\": 7, \"B\": 6, \"C+\": 5, \"C\": 4\n",
    "}\n",
    "\n",
    "extract_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"\"\"You are a subject extractor.\n",
    "        Extract SUBJECT_CODE and SUBJECT_GRADE from input text.\n",
    "        Convert grades using mapping: {grade_converter}.\n",
    "        Return ONLY JSON with key 'answer'.\"\"\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
    "])\n",
    "\n",
    "extract_chain = extract_prompt | llm_model | JsonOutputParser()\n",
    "\n",
    "# -----------------------------\n",
    "# 4. GPA Calculator Prompt\n",
    "# -----------------------------\n",
    "formula = \"((((SUBJECT_GRADE)/10)*SUBJECT_CREDIT)+...+n)/TOTAL_CREDIT_USED\"\n",
    "\n",
    "calc_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"\"\"You are a GPA calculator.\n",
    "        Rules:\n",
    "        1. Perform the calculation exactly using the provided formula.\n",
    "        2. Return ONLY JSON:\n",
    "           {{ \"answer\": <numeric_result>,\n",
    "              \"details\": {{\"SUBJECT_CODE\": \"grade*credit\"}} }}\n",
    "        3. On error, return:\n",
    "           {{ \"error\": \"<missing subject codes or issue>\" }}\"\"\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"Subjects with grades: {question}\\n\"\n",
    "        \"Reference credits: {context}\\n\"\n",
    "        \"Formula: {formula}\"\n",
    "    )\n",
    "])\n",
    "\n",
    "calc_chain = (\n",
    "    RunnableParallel({\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"context\": itemgetter(\"context\"),\n",
    "        \"formula\": itemgetter(\"formula\")\n",
    "    })\n",
    "    | calc_prompt\n",
    "    | llm_model\n",
    "    | JsonOutputParser()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Pipeline Execution\n",
    "# -----------------------------\n",
    "def run_pipeline(user_input: str):\n",
    "    # Step 1: Extract subject codes + grades\n",
    "    extracted = extract_chain.invoke({\"user_input\": user_input, \"grade_converter\": grade_converter})\n",
    "\n",
    "    # Step 2: Retrieve credits info in parallel\n",
    "    retrieved = retriever.invoke(extracted)\n",
    "\n",
    "    # Step 3: GPA Calculation\n",
    "    result = calc_chain.invoke({\n",
    "        \"question\": extracted,\n",
    "        \"context\": retrieved,\n",
    "        \"formula\": formula\n",
    "    })\n",
    "    return result\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Example Run\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = \"\"\"5SEM CB3491 Cryptography And Cyber Security B+\n",
    "                    5SEM CCS346 Exploratory Data Analysis (T & P) A\n",
    "                    5SEM CS3501 Compiler Design (T&P) A+\"\"\"\n",
    "    output = run_pipeline(user_input)\n",
    "    print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
