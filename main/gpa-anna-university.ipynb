{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4da982b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "llm_model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    api_key=os.environ[\"GOOGLE_API_KEY\"],\n",
    "    temperature=0.2  # âœ… keep deterministic for schema-based parsing\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b4309b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_loader = PyPDFLoader(\"D:\\\\NameKart\\\\React + SpringBoot\\\\ChatBot\\\\Resource\\\\B.E.CSE (1).pdf\")\n",
    "docs = pdf_loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "splits = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac4a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")\n",
    "vector_db = FAISS.from_documents(splits, embedding_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85c94dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever(search_kwargs={\"k\":800})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d287111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "extract_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"\"\"You are a subject extractor.\n",
    "        Extract SUBJECT_CODE and SUBJECT_GRADE from input text.\n",
    "        Convert grades using mapping: {grade_converter}.\n",
    "        Return ONLY JSON with key 'answer' with its grade and its subject code.\"\"\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
    "])\n",
    "\n",
    "extract_chain = extract_prompt | llm_model | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50737b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "calc_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"\"\"You are a GPA calculator.\n",
    "        Rules:\n",
    "        1. Perform the calculation exactly using the provided formula.\n",
    "        2. 0 < answer > 10.\n",
    "        3. give the answer in x.xx two decimal values. \n",
    "        4. Return ONLY JSON:\n",
    "           {{ \"answer\": <numeric_result>,\n",
    "              \"details\": {{\"SUBJECT_CODE\": \"grade*credit\"}} }}\n",
    "        5. On error, return:\n",
    "           {{ \"error\": \"<missing subject codes or issue>\" }}\"\"\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"Subjects with grades: {question}\\n\"\n",
    "        \"Reference credits: {context}\\n\"\n",
    "        \"Formula: {formula}\"\n",
    "    )\n",
    "])\n",
    "\n",
    "formula = \"[((SUBJECT_GRADE/10)*SUBJECT_CREDIT)+...+n]/TOTAL_CREDIT_USED\"\n",
    "\n",
    "calc_chain = (\n",
    "    RunnableParallel({\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"context\": itemgetter(\"context\"),\n",
    "        \"formula\": itemgetter(\"formula\")\n",
    "    })\n",
    "    | calc_prompt\n",
    "    | llm_model\n",
    "    | JsonOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c57c930a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 8.27, 'details': {'GE3252': '7*1', 'HS3252': '8*2', 'MA3251': '7*4', 'PH3256': '8*3', 'BE3251': '8*3', 'GE3251': '8*4', 'CS3251': '8*3', 'GE3272': '10*2', 'GE3271': '10*2', 'CS3271': '10*2'}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def run_pipeline(user_input: str):\n",
    "    grade_converter = {\n",
    "    \"O\": 10, \"A+\": 9, \"A\": 8, \"B+\": 7, \"B\": 6, \"C+\": 5, \"C\": 4\n",
    "    }\n",
    "    extracted = extract_chain.invoke({\"user_input\": user_input, \"grade_converter\": grade_converter})\n",
    "    retrieved = retriever.invoke(json.dumps(extracted))\n",
    "    result = calc_chain.invoke({\n",
    "        \"question\": extracted,\n",
    "        \"context\": retrieved,\n",
    "        \"formula\": formula\n",
    "    })\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = \"\"\"Tamil - II\tGE3252\tB+\t70\t61\n",
    "English - II\tHS3252 \tA\t80\t71\n",
    "Maths - II\tMA3251\tB+\t70\t61\n",
    "Physics - II\tPH3256\tA\t80\t71\n",
    "B.E(EEE)\tBE3251\tA\t80\t71\n",
    "Engineering Graphics \tGE3251\tA\t80\t71\n",
    "Program in C\tCS3251\tA\t80\t71\n",
    "Lab-English\tGE3272\tO\t100\t91\n",
    "Lab-Epl\tGE3271\tO\t100\t91\n",
    "Lab-Programming in C\tCS3271\tO\t100\t91\"\"\"\n",
    "    output = run_pipeline(user_input)\n",
    "    print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
